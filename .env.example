# Example .env file for Kanbn
# Copy this file to .env and fill in your API key

# OpenRouter (cloud-based AI)
OPENROUTER_API_KEY=your_api_key_here
OPENROUTER_MODEL=google/gemma-3-4b-it:free
# OPENROUTER_STREAM=false  # Optional: Disable streaming responses (defaults to true)

# Ollama (local AI)
# USE_OLLAMA=true  # Enable Ollama instead of OpenRouter
# OLLAMA_HOST=http://localhost:11434  # Ollama API URL
# OLLAMA_MODEL=qwen3  # Recommended model for epic decomposition

# MCP Server (Model Context Protocol)
# MCP_PORT=11434  # Port for MCP server (default: 11434)
# MCP_DEFAULT_MODEL=llama3  # Default AI model for MCP
# MCP_ALLOWED_ORIGINS=http://localhost:3000  # CORS allowed origins
# MCP_API_KEY=your_api_key_here  # Authentication key for MCP server
# MCP_TEST_MODE=false  # Enable test mode for MCP server

# Testing
# USE_REAL_API=true  # Force real API calls in test environment
